2023-05-28 16:31:54.035825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-28 16:31:54.046682: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-28 16:31:54.049962: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-28 16:31:55.431431: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-28 16:31:55.436452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-28 16:31:55.450366: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-28 16:31:55.512802: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-28 16:31:56.665638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-28 16:31:56.666921: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-28 16:31:56.667967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-28 16:31:56.668945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20406 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:01:00.0, compute capability: 8.6
all_x.shape:  (4836, 32, 7)
all_t.shape:  (4836, 32, 1)
all_y.shape:  (4836, 32)
Total number of sequences: 4836
train_x.shape:  (3869, 32, 7)
train_t.shape:  (3869, 32, 1)
train_y.shape:  (3869, 32)
Total number of train sequences: 3869
Total number of test  sequences: 967
  0%|          | 0/31 [00:00<?, ?it/s]2023-05-28 16:31:57.263081: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
2023-05-28 16:31:57.874531: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201
2023-05-28 16:31:58.596451: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
  3%|▎         | 1/31 [00:01<00:56,  1.87s/it]  6%|▋         | 2/31 [00:02<00:28,  1.02it/s] 10%|▉         | 3/31 [00:02<00:19,  1.44it/s] 13%|█▎        | 4/31 [00:02<00:15,  1.80it/s]WARNING:tensorflow:5 out of the last 5 calls to <function IFGSM.__call__ at 0x7f85b807e670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
 16%|█▌        | 5/31 [00:03<00:12,  2.05it/s]WARNING:tensorflow:6 out of the last 6 calls to <function IFGSM.__call__ at 0x7f85582a85e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
 19%|█▉        | 6/31 [00:03<00:11,  2.25it/s] 23%|██▎       | 7/31 [00:03<00:09,  2.45it/s] 26%|██▌       | 8/31 [00:04<00:08,  2.60it/s] 29%|██▉       | 9/31 [00:04<00:08,  2.70it/s] 32%|███▏      | 10/31 [00:05<00:08,  2.54it/s] 35%|███▌      | 11/31 [00:05<00:07,  2.65it/s] 39%|███▊      | 12/31 [00:05<00:06,  2.75it/s] 42%|████▏     | 13/31 [00:06<00:06,  2.81it/s] 45%|████▌     | 14/31 [00:06<00:05,  2.85it/s] 48%|████▊     | 15/31 [00:06<00:05,  2.90it/s] 52%|█████▏    | 16/31 [00:07<00:05,  2.96it/s] 55%|█████▍    | 17/31 [00:07<00:04,  2.98it/s] 58%|█████▊    | 18/31 [00:07<00:04,  3.00it/s] 61%|██████▏   | 19/31 [00:08<00:04,  3.00it/s] 65%|██████▍   | 20/31 [00:08<00:03,  3.01it/s] 68%|██████▊   | 21/31 [00:08<00:03,  2.96it/s] 71%|███████   | 22/31 [00:09<00:03,  2.67it/s] 74%|███████▍  | 23/31 [00:09<00:02,  2.78it/s] 77%|███████▋  | 24/31 [00:09<00:02,  2.86it/s] 81%|████████  | 25/31 [00:10<00:02,  2.92it/s] 84%|████████▍ | 26/31 [00:10<00:01,  2.97it/s] 87%|████████▋ | 27/31 [00:10<00:01,  3.00it/s] 90%|█████████ | 28/31 [00:11<00:00,  3.02it/s] 94%|█████████▎| 29/31 [00:11<00:00,  3.02it/s] 97%|█████████▋| 30/31 [00:11<00:00,  3.03it/s]100%|██████████| 31/31 [00:12<00:00,  3.05it/s]100%|██████████| 31/31 [00:12<00:00,  2.55it/s]
total_loss: 1.6745635271072388 	 total_accuracy: 0.5732613753877973
(967, 32)
